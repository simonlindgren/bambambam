{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import classy_classification\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': ['My head aches, and I will need some rest.', 'I feel a sense of hunger in my stomach.', 'She was unable to straighten her fingers.'], 'clothes': ['I will get my hat and coat, and I think also my umbrella.', 'Shoes are good to wear.', 'The trousers are striped, and my pockets are empty.'], 'ghosts': ['This is spooky, and the night is dark.', 'A phantom is fleeting across my room.', 'A ghastly shape is hiding behind my curtain.']}\n"
     ]
    }
   ],
   "source": [
    "label_files = glob.glob('labels/*.txt')\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for lf in label_files:\n",
    "    label = lf.split('/')[1].split('.')[0]\n",
    "    examples = [e.strip() for e in open(lf).readlines()]\n",
    "    labels[label] = examples\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classy_classification.classifiers.classy_spacy.ClassySpacyExternalFewShot at 0x3484471c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with a blank spacy model\n",
    "nlp = spacy.blank(\"en\") \n",
    "\n",
    "# add in the text_categorizer from classy_classification to the processing pipeline\n",
    "nlp.add_pipe(\"text_categorizer\",\n",
    "    config ={\n",
    "    \"data\": labels,\n",
    "    \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"device\": \"cpu\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i.strip() for i in open('data/unseen.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classification\n",
    "sents = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "for s in sentences:\n",
    "    sents.append(s)\n",
    "    scores.append(nlp(s)._.cats)\n",
    "    break\n",
    "\n",
    "df = pd.DataFrame(zip(sents,scores), columns = ['text', 'scores'])\n",
    "df = pd.concat([df.drop(['scores'], axis=1), df['scores'].apply(pd.Series)], axis=1)\n",
    "df.to_csv('bambambam.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value1</td>\n",
       "      <td>value2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value3</td>\n",
       "      <td>value4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key1    key2\n",
       "0  value1  value2\n",
       "1  value3  value4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create example DataFrame\n",
    "df = pd.DataFrame({'dict_col': [{'key1': 'value1', 'key2': 'value2'},\n",
    "                                {'key1': 'value3', 'key2': 'value4'}]})\n",
    "\n",
    "# apply pd.Series constructor to each row of dict_col\n",
    "df = pd.concat([df.drop(['dict_col'], axis=1), df['dict_col'].apply(pd.Series)], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'furniture': 0.12022529596456778, 'kitchen': 0.8797747040354322}\n"
     ]
    }
   ],
   "source": [
    "# run classification\n",
    "print(nlp(\"I am looking for kitchen appliances.\")._.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = 'My first birthday was great. My 2. was even better.'\n",
    "sentences = [i for i in nlp(text).sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[My first birthday was great., My 2. was even better.]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = spacy.blank(\"en\")\n",
    "\n",
    "sentence_model.add_pipe(\"sentencizer\")\n",
    "\n",
    "with open (\"harry_potter_cleaned.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "sentences = sentence_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ","
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "for sentence in sentences.sents:\n",
    "    doc = nlp(sentence.text) #< -- perform the categorizer at the sentence level\n",
    "    final_data.append({\"sentence\": doc.text, \"cats\": doc._.cats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.',\n",
       " 'cats': {'furniture': 0.588502517277626, 'kitchen': 0.4114974827223741}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/simon/Dropbox/code/science2/few_shot.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simon/Dropbox/code/science2/few_shot.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m final_data:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simon/Dropbox/code/science2/few_shot.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m item[\u001b[39m\"\u001b[39;49m\u001b[39mcats\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mfear\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39m.8\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simon/Dropbox/code/science2/few_shot.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mprint\u001b[39m (item[\u001b[39m\"\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstrip())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simon/Dropbox/code/science2/few_shot.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m (item[\u001b[39m\"\u001b[39m\u001b[39mcats\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fear'"
     ]
    }
   ],
   "source": [
    "for item in final_data:\n",
    "    if item[\"cats\"][\"fear\"] > .8:\n",
    "        print (item[\"sentence\"].strip())\n",
    "        print (item[\"cats\"])\n",
    "        print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebe3ce01678291323dcff905f7209dd16179ba179af5ccfbed7b023ef5b6c3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
